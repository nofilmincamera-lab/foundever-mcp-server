# Foundever MCP Server

> **Enterprise RFP Response Generation System**
> MCP server with fine-tuned AI models for Foundever-style professional proposal writing

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

## Overview

The Foundever MCP (Model Context Protocol) Server is a comprehensive system for generating professional RFP responses using Foundever's established writing standards. It combines semantic search over 600K+ evidence claims with fine-tuned language models to ensure consistent, high-quality proposal content.

### Key Features

- ğŸ¤– **33 Specialized MCP Tools** - From claim search to fabrication detection
- ğŸ” **600K+ Evidence Claims** - Qdrant vector database with semantic search
- ğŸ¯ **Fine-tuned Models** - Qwen2.5-32B trained on 3,888 Foundever examples
- ğŸ“ **Style Guide Enforcement** - Automated voice and compliance checking
- ğŸš« **No-Fabrication Policies** - LLM-powered fact verification
- ğŸ“Š **Persona-Based Search** - Tailored for financial services clients
- ğŸ” **Proof-Tier System** - T0 marketing â†’ T3 third-party evidence

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude / MCP Client                            â”‚
â”‚  https://mcp.riorock.app/mcp/messages           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MCP Server (Port 8420)                         â”‚
â”‚  - 33 Tool Endpoints                            â”‚
â”‚  - Request handling & validation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Enrichment Engine                              â”‚
â”‚  - Style guide enforcement                      â”‚
â”‚  - Voice conversion                             â”‚
â”‚  - Evidence integration                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Search (E5-Mistral-7B)                â”‚
â”‚  - Claims: 600K vectors (4096-dim)              â”‚
â”‚  - Chunks: 135K vectors (2048-dim)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Qdrant Vector Database (Port 6333)             â”‚
â”‚  - claims collection                            â”‚
â”‚  - unified_chunks collection                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ollama + Foundever Voice Model (Port 11434)    â”‚
â”‚  - foundever-voice-q5:latest (22GB, Q5_K_M)     â”‚
â”‚  - foundever-voice-f16:latest (62GB, F16)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Quick Start

### Prerequisites

- Python 3.10+
- CUDA-capable GPU (recommended: 16GB+ VRAM)
- Qdrant vector database
- Ollama (for model serving)

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/foundever-mcp-server.git
cd foundever-mcp-server

# Run setup script
./scripts/setup.sh

# Or manual setup:
pip install -r requirements.txt
```

### Start Server

```bash
# Start MCP server
python src/mcp_server.py 8420

# Or as systemd service
sudo systemctl start foundever-mcp.service
```

### Load Model

```bash
# Load quantized model (recommended)
./scripts/foundever_load_model.sh foundever-voice-q5

# Or use interactive manager
./scripts/foundever_model_manager.sh
```

### Configure Claude Desktop

Add to `~/.config/claude/claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "foundever-style-guide": {
      "url": "http://localhost:8420/mcp/messages"
    },
    "ollama": {
      "command": "npx",
      "args": ["-y", "mcp-ollama"],
      "env": {
        "OLLAMA_HOST": "http://localhost:11434",
        "OLLAMA_MODEL": "foundever-voice-q5:latest"
      }
    }
  }
}
```

## Repository Structure

```
foundever-mcp-server/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                   # Git ignore patterns
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ mcp_server.py           # Main MCP server (33 tools)
â”‚   â”œâ”€â”€ enrichment_engine.py    # Style guide enrichment
â”‚   â”œâ”€â”€ search.py               # Qdrant semantic search
â”‚   â”œâ”€â”€ embedder.py             # E5-Mistral embeddings
â”‚   â”œâ”€â”€ config.py               # Configuration & personas
â”‚   â”œâ”€â”€ document_tools.py       # RFP document parsing
â”‚   â”œâ”€â”€ main.py                 # CLI interface
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ scripts/                     # Management scripts
â”‚   â”œâ”€â”€ setup.sh                # Initial setup
â”‚   â”œâ”€â”€ foundever_load_model.sh # Model loader
â”‚   â”œâ”€â”€ foundever_model_manager.sh # Interactive model manager
â”‚   â”œâ”€â”€ start_server.sh         # Start MCP server
â”‚   â””â”€â”€ FOUNDEVER_MODELS_README.md # Model documentation
â”‚
â”œâ”€â”€ models/                      # Model information
â”‚   â”œâ”€â”€ README.md               # Model details
â”‚   â”œâ”€â”€ Modelfile.q5           # Ollama Q5_K_M config
â”‚   â””â”€â”€ Modelfile.f16          # Ollama F16 config
â”‚
â”œâ”€â”€ config/                      # Configuration files
â”‚   â”œâ”€â”€ mcp_config.json         # MCP server config
â”‚   â”œâ”€â”€ claude_desktop_config.json # Claude Desktop config
â”‚   â””â”€â”€ qdrant_config.yaml      # Qdrant settings
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ DOCUMENTATION.md        # Complete technical docs
â”‚   â”œâ”€â”€ README.md               # Original readme
â”‚   â”œâ”€â”€ API.md                  # API reference
â”‚   â”œâ”€â”€ TOOLS.md                # Tool descriptions
â”‚   â”œâ”€â”€ TRAINING.md             # Model training guide
â”‚   â””â”€â”€ DEPLOYMENT.md           # Production deployment
â”‚
â””â”€â”€ tests/                       # Test suite
    â”œâ”€â”€ test_mcp_server.py
    â”œâ”€â”€ test_enrichment.py
    â””â”€â”€ test_search.py
```

## MCP Tools (33 Total)

### Core Search Tools
- `search_claims` - Semantic search across 600K+ claims
- `search_by_persona` - Persona-tailored search (PayTech, Banks, etc.)
- `enrich_section` - Enrich content with evidence
- `convert_to_practitioner_voice` - Marketing â†’ practitioner conversion

### Style Guide Tools
- `get_style_guide` - Complete Foundever style guide
- `get_narrative_templates` - Narrative pattern templates
- `check_voice` - Voice analysis (marketing vs practitioner)
- `build_section` - Generate proposal sections

### Research & Validation
- `get_research_guidelines` âš ï¸ **CRITICAL** - Research protocol
- `validate_claim` - Claim validation with confidence levels
- `check_qdrant_coverage` - Check evidence availability
- `check_content_compliance` - Scan for violations

### No-Fabrication Tools
- `get_no_fabrication_policy` - Strict no-fabrication rules
- `generate_iteration_request` - Request missing information
- `check_for_fabrication` - Detect fabricated content
- `llm_fact_check` - LLM-powered final verification

### RFP Input Handling
- `parse_rfp_requirements` - Parse client documents
- `generate_clarifying_questions` - Generate questions
- `map_to_style_guide_structure` - Map to proposal structure
- `track_assumptions` - Track unconfirmed assumptions

### Financial Services
- `get_finserv_persona` - 12 FinServ persona types
- `get_threat_context` - Threat descriptions (APP fraud, etc.)
- `get_finserv_metrics` - Metrics that matter

[See complete tool list in docs/TOOLS.md](docs/TOOLS.md)

## Model Information

### Foundever Voice Model

**Base:** Qwen/Qwen2.5-32B-Instruct
**Training Date:** 2026-01-27
**Training Examples:** 3,888
**Validation Examples:** 433
**Epochs:** 3
**LoRA r/alpha:** 16/32

**Dataset Composition:**
- Original voice patterns: 372
- Enhanced database: 2,469
- Synthetic: 1,480
- **Total:** 4,321

### Available Versions

| Version | Size | Quality | VRAM | Use Case |
|---------|------|---------|------|----------|
| **Q5_K_M** âœ… | 22GB | Very Good | ~14GB | Recommended for most work |
| F16 | 62GB | Highest | ~35GB | Final production drafts |

**Model Locations:**
- F16: `/media/willard/New Volume/foundever_model/`
- Q5_K_M: `/media/willard/New Volume/foundever_model_quantized/`

[See complete model documentation](scripts/FOUNDEVER_MODELS_README.md)

## Configuration

### Environment Variables

```bash
# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=foundever-voice-q5:latest

# MCP Server
MCP_PORT=8420
MCP_HOST=0.0.0.0
```

### Qdrant Collections

Required collections:
- `claims` - 600K+ vectors (4096-dim, E5-Mistral-7B)
- `unified_chunks` - 135K vectors (2048-dim)

## Development

### Running Tests

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_mcp_server.py

# With coverage
pytest --cov=src tests/
```

### Code Style

```bash
# Format code
black src/

# Lint
ruff check src/

# Type checking
mypy src/
```

## Deployment

### Production Setup

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for:
- Systemd service configuration
- Nginx reverse proxy setup
- SSL/TLS configuration
- Monitoring and logging
- Backup strategies

### Public Endpoint

The server can be exposed via Tailscale + Caddy:
- **Local:** http://localhost:8420
- **Tailscale:** http://100.120.219.80:8420
- **Public:** https://mcp.riorock.app

## Documentation

- [Complete Documentation](docs/DOCUMENTATION.md) - Full technical reference
- [API Reference](docs/API.md) - MCP API endpoints
- [Tool Reference](docs/TOOLS.md) - All 33 tools detailed
- [Training Guide](docs/TRAINING.md) - Model training process
- [Model README](scripts/FOUNDEVER_MODELS_README.md) - Model management

## Troubleshooting

### Common Issues

**Ollama not responding:**
```bash
# Check Ollama status
pgrep ollama

# Start Ollama
ollama serve &

# Load model
./scripts/foundever_load_model.sh foundever-voice-q5
```

**MCP server not starting:**
```bash
# Check port availability
lsof -i :8420

# Check logs
tail -f /var/log/foundever-mcp/mcp_server.log
```

**Qdrant connection failed:**
```bash
# Check Qdrant status
curl http://localhost:6333/health

# Start Qdrant
docker start qdrant
```

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## License

MIT License - see [LICENSE](LICENSE) file

## Credits

- **Base Model:** Qwen/Qwen2.5-32B-Instruct (Alibaba Cloud)
- **Embeddings:** intfloat/e5-mistral-7b-instruct
- **Vector DB:** Qdrant
- **Model Serving:** Ollama
- **Framework:** MCP (Model Context Protocol)

## Support

- **Issues:** [GitHub Issues](https://github.com/yourusername/foundever-mcp-server/issues)
- **Documentation:** [docs/](docs/)
- **Model Info:** [scripts/FOUNDEVER_MODELS_README.md](scripts/FOUNDEVER_MODELS_README.md)

---

**Built for Foundever RFP Excellence** ğŸš€
